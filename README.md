# Multilingual Sign Language Detection using YOLOv5
This project aims to detect and classify hand gestures in sign languages from multiple cultures and languages using the YOLOv5 object detection algorithm. 

## Steps to run the application:

1. git clone https://github.com/rutvijjoshi26/Multilingual-Sign-Language-Detection-using-YOLOv5.git

2. cd Multilingual-Sign-Language-Detection-using-YOLOv5

3. yarn install 

4. yarn start

The application has a user interface that allows the user to select the detection mode, language, and upload an image or video file for detection. The application supports the following detection modes:

**Image Upload**: Allows the user to upload an image file for detection. The detected signs are displayed on the image.<br />
**Video Upload**: Allows the user to upload a video file for detection. The detected signs are displayed on the video.<br />
**Live Detection**: Allows the user to use the device camera for real-time sign detection. The detected signs are displayed on the video feed.<br />

The application supports the detection and classification of the following sign languages:

**English**<br />
**Marathi**<br />
**Hindi**
